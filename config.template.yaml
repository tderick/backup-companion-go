# -----------------------------------------------------------------------------
# Welcome to the Backup Companion Configuration File
#
# This file defines everything the backup tool needs to know:
#   1. SOURCES: What can be backed up (your databases and directories).
#   2. DESTINATIONS: Where the backups should be sent (your S3 buckets).
#   3. JOBS: Which sources to back up and which destinations to send them to.
#
# How to use:
#   - Rename this file from 'config.template.yaml' to 'config.yaml'.
#   - Fill in your specific details for each section.
#   - Run the tool by pointing it to a job name, e.g., `backup-companion backup my_job_name`
#
# For more information, visit the project documentation at [YOUR_PROJECT_URL]
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# STEP 1: DEFINE ALL POSSIBLE SOURCES
#
# In this section, you define every database and directory that the tool might
# need to back up. Each source is given a unique name (e.g., `production_db`)
# which you will use later to reference it in your backup jobs.
# -----------------------------------------------------------------------------
sources:
  # 'databases' is a collection of all your database connections.
  databases:
    # This is a unique, friendly name for your database. Use this name in the 'jobs' section.
    # Example: 'production_db', 'staging_db', 'billing_api_db'.
    production_db:
      # Supported values: "postgres", "mysql"
      driver: "postgres"
      # The hostname or IP address of your database server.
      host: "prod.db.internal"
      # The port your database is running on (e.g., 5432 for PostgreSQL).
      port: 5432
      # The database user with backup privileges.
      user: "backup_user"
      # The password for the database user. 
      # Recommended: Set via BACKUP_COMPANION_DB_PASSWORD_{NAME} environment variable
      # Example: BACKUP_COMPANION_DB_PASSWORD_PRODUCTION_DB="mysecret"
      password: ""
      # The specific name of the database you want to back up.
      name: "production_database"

    staging_db:
      driver: "mysql"
      host: "staging.db.internal"
      port: 3306
      user: "backup_user"
      password: ""
      name: "staging_database"

  # 'directories' is a collection of all the filesystem paths you might want to back up.
  directories:
    # A unique, friendly name for your directory source.
    main_app_files:
      # The absolute path to the directory you want to include in the backup.
      path: "/var/www/my-app"

    user_uploads:
      path: "/var/www/my-app/uploads"

    nginx_configs:
      path: "/etc/nginx"

# -----------------------------------------------------------------------------
# STEP 2: DEFINE ALL POSSIBLE DESTINATIONS
#
# This is where you configure your cloud storage providers. Currently, S3-compatible
# storage is supported. Each destination is given a unique name so you can
# easily reference it in your backup jobs.
# -----------------------------------------------------------------------------
destinations:
  # A unique, friendly name for this storage destination.
  contabo_primary:
    # Currently only "s3" is supported
    provider: "s3"
    # The name of the S3 bucket to upload backups to.
    bucketName: "main-backup-bucket"
    # Your S3 Access Key ID.
    # Recommended: Set via BACKUP_COMPANION_S3_KEY_{NAME} environment variable
    # Example: BACKUP_COMPANION_S3_KEY_CONTABO_PRIMARY="mykey"
    accessKeyId: ""
    # Your S3 Secret Access Key.
    # Recommended: Set via BACKUP_COMPANION_S3_SECRET_{NAME} environment variable
    # Example: BACKUP_COMPANION_S3_SECRET_CONTABO_PRIMARY="mysecret"
    secretAccessKey: ""
    # The AWS region of your bucket (e.g., 'us-east-1', 'eu-central-1').
    region: "eu-2"
    # For non-AWS S3 providers, you must provide the full endpoint URL.
    # For AWS S3, this can be omitted.
    endpointUrl: "https://s3.eu-2.contabo.com"

  aws_archive:
    provider: "s3"
    bucketName: "long-term-archive-bucket"
    accessKeyId: ""
    secretAccessKey: ""
    region: "us-east-1"

# -----------------------------------------------------------------------------
# STEP 3: DEFINE THE BACKUP JOBS
#
# A 'job' ties everything together. It defines a specific backup task by
# referencing sources and destinations you defined above. You run a job from
# the command line using its name.
# -----------------------------------------------------------------------------
jobs:
  # This is the name of the job you will run, e.g., `backup-companion backup full_backup`.
  full_backup:
    # The output configuration for the local backup file before upload
    output:
      # Local directory where backup file will be temporarily stored
      dir: "/tmp/backups"
      # Name format: {name}-{timestamp}.tar.gz
      # Example: full-backup-2024-01-20-153022.tar.gz
      name: "full-backup"

    # List of databases to include (must match names from sources.databases)
    databases:
      - "production_db"
      - "staging_db"

    # List of directories to include (must match names from sources.directories)
    directories:
      - "main_app_files"
      - "nginx_configs"

    # List of destinations to upload to (must match names from destinations)
    destinations:
      - "contabo_primary"
      - "aws_archive"

  # An example of a job that only backs up databases
  database_only:
    output:
      dir: "/tmp/backups"
      name: "database-backup"
    databases:
      - "production_db"
    destinations:
      - "contabo_primary"

  # An example of a job that only backs up files
  files_only:
    output:
      dir: "/tmp/backups"
      name: "files-backup"
    directories:
      - "main_app_files"
      - "nginx_configs"
    destinations:
      - "contabo_primary"